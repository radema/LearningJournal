Continuing a bit the series of reducing the getpocket backlog

### #1 
#AI 
Long topic on [[AI ethics]] and regulation. 
Main ideas:
* Meaningful transparency of algorithmic systems
* Public-interest groups play a critical role in uncovering AI regulation

A comprehensive framework on ethical AI should include the following:

-   a clear definition of the _object_ to assess ( → the AI system);
-   broad buy-in on the _ideal_ to achieve;
-   well-defined _principles_ to help achieve our stated ideal;
-   a set of _stakeholder groups_ with defined responsibilities to help promote the achievement of our ideal.

#### The unit
Consider the entire decision-making system and its components, like:
* data
* algorithms
* human in the loop

#### The ideal
actually is defined as _responsibility_
-   System owners are held accountable for developing, deploying and monitoring their algorithmic systems to avoid harms;
-   System users are adequately trained on the limitations of ADS and have agency to reason about the system outcome;
-   Impacted groups are empowered to provide feedback, flag harms and seek recourse;
-   Government actors are accountable for setting adequate regulatory safeguards and establishing avenues for recourse.


> -   **Fair and non-discriminatory:** actively assesses, monitors, and mitigates bias; aims to produce properly calibrated fairer outcomes and decisions
> -   **Explainable:** able to produce interpretable justification for the decisions produced
> -   **Secure**: enacts effective controls to protect system from threats; actively flags and mitigates vulnerabilities
> -   **Robust**: consistently meets accuracy and performance requirements and is robust to perturbations
> -   **Upholds data privacy rights:** protects data privacy rights and conforms to existing data laws for both direct and indirect users
> -   **Safe**: avoids harm for impacted users and aims to promote human wellbeing


> Second-order principles are necessary to ensure abidance with the requirements outlined above. These include:

> -   **Ensuring transparency of the ADS:** at a basic level, transparency translates to system visibility, and at a more sophisticated level, it reflects the system’s performance on first-order principles. _More nuance on transparency is provided in subsequent articles._
> -   **Ensuring accountability of the ADS system:** this refers to the system’s owner ability to explain their actions (and failings) and take responsibility for them. ADS transparency is a pre-requisite to achieve accountability. Accountability can be enforced via assessments, audits, and feedback loops.
> -   **Preserving human agency and possibility for recourse:** when an ADS fails and adversely impacts an individual, the concerned individual should have a clear recourse process to follow in order to rectify the error. Strong transparency and accountability mechanisms should be in place to enable recourse.

![[Responsible Use of Algorithmic Decision Makying Systems.png]]

References:
* [Beyond the "Black Box", PhD Thesis by Murad Maya](https://dspace.mit.edu/handle/1721.1/139092)
* [Maya Murad's article on Medium](https://towardsdatascience.com/back-to-basics-revisiting-the-responsible-ai-framework-847fd3ec860b)

I study in the next weeks this subject.

---

### #2 
article on MIT review about the AI act in the european union. 
* first law that aims to regulate the whole sector.
* The bill requires people to be notified when they encounter deepfakes, biometric recognition systems, or AI applications that claim to be able to read their emotions.
* a ban on predictive policing systems
* It will be at least another year before a final text is set in stone, and a couple more years before businesses will have to comply.

---

### #3 
article on python code readability and [[Best practice]]. Interesting but at the moment is not a priority. However, I realized that I should build a page about best practices

---

