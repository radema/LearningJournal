Continuing a bit the series of reducing the getpocket backlog
Topics: #MarketBasketAnalysis #ml #Ranking

# Data Mining: [[Market Basket Analysis]] with Apriori Algorithm

Market Basket Analysis -> to uncover associations between item
It allows to carry out the following strategies:
1. Associated products are placed close to each other, so that buyers of one item would be prompted to buy the other.
2. Discounts can be applied to only one of the associated products.

Algorithm used is Association Rule Mining, rule-based machine learning method that helps to uncover meaningful correlations between different products. 

Core concepts:
* **Support**, the plain basic (*empirical*) probability of an event to occur. 
* **Confidence**, is the conditional probability of an event respect to another one. 
* **Lift**, the *observed to expect ration* (o/e) which measures how likely an item is purchased when another item is purchased, while controlling for how popular both items are. (correlation-like measure)

The Apriori Algorithm is one of the most famous association rules mining algorithms. 

# [[Artificial Counterfactual Estimation]] (ACE): Machine Learning-Based Causal Inference at Airbnb
 **ACE (Artificial Counterfactual Estimation)**, which leverages machine learning (ML) and causal inference to artificially reproduce the “counterfactual” scenario produced by random assignment.
 
 # Learning to Rank: A Complete Guide to [[Ranking]] using Machine Learning
 
 **Ranking**: sorting elements by relevance with respect to a query.
 It is a fundamental problem of Information Retrieval and related to several applications such as:
 * search engines
 * recommender systems

> Ranking models typically work by predicting a **relevance score _s = f_(_x_)** for each input **_x_ = (_q, d_)** where **_q_** **is a** **query** and **_d_** **is a document**. Once we have the relevance of each document, we can sort (i.e. rank) the documents according to those scores.

The scoring model can use various approaches such as:
* Vector space models: Compute a vector embedding for each query and document, and then compute the relevance score as the cosine similarity <- unsupervised approach
* Learning to rank: The scoring model is a Machine Learning model that learns to predict a score **_s_** given an input **_x_ = (_q, d_)** during a training phase where some sort of ranking loss is minimized. <- supervised approach

This is the same problem encoutered in the [Kaggle's competition "US Patent Phrase to Phrase Matching"](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/overview).

Useful metrics to learn to rank:
* Mean Average Precision -> useful for binary results
* Discounted Cumulative Gain -> useful for graded results

Useful Loss Function
* pointswise method -> task is a regression
* pairwise method -> task is a binary classification
* listwise -> include metric in loss function ->improved results

The last approach has been exploited in the [following paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/1e34e05e5e4bf2d12f41eb9ff29ac3da9fdb4de3.pdf) by Google. 

> You can find the state-of-the-art implementation of LambdaRank in LightGBM. It is a very nicely designed and easy to use Python package with a friendly scikit-learn like interface. It is also the version that LambdaLoss used as a reference to benchmark their own algorithm. [See here for details](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRanker.html)


# Price Recommendation System Modeling Using PyCaret and Deep Learning

based on a pycaret tutorial. It reduce the price recommendation problem to a regression problem. 
